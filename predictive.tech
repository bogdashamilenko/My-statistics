#We are using data set marketing with the dependant variable Union. It is bonomial o we will perform binomial type of regression to predict
#whether they will be union member or not. There are three independant variables: age(continuous), satisfaction with the job(ordinal) and 
#political view(categorical nominal). 
#First of all we are checking assumptions of outliers and multicollinearity of independant variables. 

> df <- df[,c(2,6,7,8)]
> df.indep <- df[,c(1,2,4)]
> install.packages('usdm')
> vif(df.indep)
  Variables      VIF
1       age 1.216778
2    jobsat       NA
3   polview       NA
#The only numeric variable is age and the Variance Inflation Factor is less than 10, so we can continue as there is no multicollinearity. 
> ggplot(df,aes(union,age))+geom_boxplot()

#Now we can see that both groups do not present outliers at all, so we can continue with the regression.
> model <- glm(union~age+jobsat+polview,data=df,family=binomial)
> summary(model)
#The table quite large so I would not post it, though all parameters are not statistically significant as they are higher than 5%, though
#the Age has importance of 0.0521 and category of people  who has extremely conservative political view has p-value equal to 0.0865.
> expb <- exp(coef(model))
> expb
#Let`s take a look at coefficients which are close to be important and people with the higher age has 4% more chances to be a union
#member than younger people. Also, citizens with extremely conservative political views has 60.9% to be a union member. Other factors
#do not have importance. 

#Let`s continue with the goodness-of-fit calculations and we will start with Hosmer-Lemeshow statistics. It should be >5% if the model 
#performed well.
> library(ResourceSelection)
> hoslem.test(df$union,fitted(model))
	Hosmer and Lemeshow goodness of fit (GOF) test
data:  df$union, fitted(model)
X-squared = 5000, df = 8, p-value < 2.2e-16
> library(fmsb)
> NagelkerkeR2(model)
$`N`
[1] 5000
$R2
[1] 0.0038312
#As we can see, the model performed really poor, as it describes only 0.3% of results. Though let`s continue our exploration.
> library(BaylorEdPsych)
> PseudoR2(model)
        McFadden     Adj.McFadden        Cox.Snell       Nagelkerke McKelvey.Zavoina 
    2.591051e-03    -3.574953e-03     2.182736e-03     3.831200e-03     4.964377e-03 
          Effron            Count        Adj.Count              AIC    Corrected.AIC 
    2.257911e-03               NA               NA     4.229744e+03     4.229806e+03 
\\\\\\\\\\\\\\\\\\\\\\\\\\\\\

#Now we will be using the same data but we will choose different dependant and independant variables as we are going to perform
#multiniomial regression. Dpendant variable is the type of card:
> table (df$card)
American Express         Discover       Mastercard            Other             Visa 
            1000             1333             1202              215             1250 
#And our independant variables are: age(continuous), gender(dichotomus or binomial) and age(continuous).
#The assumptions remain the same as for the binomial regression: Outliers and multicollinearity. 

> df <- df[,c(1,2,3,5)]
> ggplot(df,aes(card,age))+geom_boxplot()
> ggplot(df,aes(card,income))+geom_boxplot()
#On the boxplot we can see numerous significant outliers that may negatively influence our model. To make our model cleaner, let`s
#get rid of the most important outliers, i.e. people with the salary higher than 300,000.
> df <- subset(df,income<300)
> ggplot(df,aes(card,income))+geom_boxplot()
#Looks a bit better right now, we have deleted 34 observations from 5,000 and now we can continue with the multinomial analysis.
#First of all we will pick up a reference category for each variable that is categorical, both dependant and independant.

> df$gender <- relevel(df$gender, ref = 'Male')
> df$card <- relevel(df$card, ref = "Other")
> library(nnet)
> model<- multinom(card~gender+age+income,data=df)
> summary(model)
Coefficients:
                 (Intercept) genderFemale          age     income
American Express    1.252334   -0.8324198 -0.002090151 0.01793280
Discover            1.054368   -0.4531345  0.002069272 0.01997840
Mastercard          1.141782   -0.3550897  0.005953687 0.01224755
Visa                1.281010   -0.2452058  0.004374856 0.01042260

#We now have coefficients of the model, though it is better to interpret their antilogariphms.
> summ <- summary(model)
> z <- summ$coefficients/summ$standard.errors
> pv <- pnorm(abs(z),lower.tail = F)*2
> pv
                  (Intercept) genderFemale       age       income
American Express 8.323888e-08 7.884441e-08 0.6127259 5.787055e-10
Discover         4.747736e-06 2.804839e-03 0.6065860 3.063833e-12
Mastercard       7.508746e-07 1.941748e-02 0.1351036 2.324264e-05
Visa             2.452345e-08 1.054975e-01 0.2695227 3.293312e-04
#As we can see from the model results, all categories and variable except age are statistically significant and they differ from
#our baselines.

#
